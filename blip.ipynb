{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ed6617-f1da-4df4-89dd-142c3ecdc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/achobe/miniforge3/lib/python3.10/site-packages (4.46.2)\n",
      "Requirement already satisfied: Pillow in /Users/achobe/miniforge3/lib/python3.10/site-packages (11.0.0)\n",
      "Requirement already satisfied: torch in /Users/achobe/miniforge3/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/achobe/miniforge3/lib/python3.10/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /Users/achobe/miniforge3/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Generated Caption: a man with a beard drinking a cup of tea\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers Pillow torch torchvision torchaudio\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "# Initialize the processor and model from Hugging Face\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# Load an image\n",
    "image = Image.open(\"/Users/achobe/ibm_course/blip/chai.jpg\")\n",
    "# Prepare the image\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "# Generate captions\n",
    "outputs = model.generate(**inputs)\n",
    "caption = processor.decode(outputs[0],skip_special_tokens=True)\n",
    " \n",
    "print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa5eaf0-2cf8-47a0-88d2-03fb5a37ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/achobe/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.20.3-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, Pillow, numpy, networkx, fsspec, torch, huggingface-hub, torchvision, torchaudio, tokenizers, transformers\n",
      "Successfully installed Pillow-11.0.0 fsspec-2024.10.0 huggingface-hub-0.26.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 transformers-4.46.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achobe/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/achobe/miniforge3/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a man eating a hamburger\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers Pillow torch torchvision torchaudio\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "# Initialize the processor and model from Hugging Face\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# Load an image\n",
    "image = Image.open(\"/Users/achobe/ibm_course/blip/man_eating.jpg\")\n",
    "# Prepare the image\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "# Generate captions\n",
    "outputs = model.generate(**inputs)\n",
    "caption = processor.decode(outputs[0],skip_special_tokens=True)\n",
    " \n",
    "print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff36c82-d254-4ed1-aa2f-6635a3c21eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photography of a woman and her dog on the beach\n",
      "woman sitting on the beach with her dog and a cell phone\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "# conditional image captioning\n",
    "text = \"a photography of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n",
    "# unconditional image captioning\n",
    "inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc95af6-6672-484a-a4ad-47226eb07233",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'gradio' has no attribute 'Interface' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreet\u001b[39m(name, intensity):\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mint\u001b[39m(intensity)\n",
      "File \u001b[0;32m~/ibm_course/blip/gradio.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreet\u001b[39m(name, intensity):\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mint\u001b[39m(intensity)\n\u001b[0;32m----> 5\u001b[0m demo \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m(\n\u001b[1;32m      6\u001b[0m   fn\u001b[38;5;241m=\u001b[39mgreet,\n\u001b[1;32m      7\u001b[0m   inputs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslider\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m   outputs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m demo\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'gradio' has no attribute 'Interface' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def greet(name, intensity):\n",
    "  return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "demo = gr.Interface(\n",
    "  fn=greet,\n",
    "  inputs=[\"text\", \"slider\"],\n",
    "  outputs=[\"text\"],\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3cfdb-1338-4806-b8bc-7b857ca5e8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
